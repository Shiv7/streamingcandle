# ============================================================================
# STREAMINGCANDLE - END-TO-END PIPELINE CONFIGURATION
# ============================================================================
# Combined: NEW family candle pipeline + EXISTING strategy modules

spring.profiles.default=production
spring.application.name=streamingcandle
server.port=${SERVER_PORT:8081}

# ============================================================================
# KAFKA STREAMS CONFIGURATION
# ============================================================================
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
spring.kafka.streams.application-id=${KAFKA_APP_ID:unified-family-processor-v2}
spring.kafka.streams.client-id=streamingcandle-family
# FIXED: Use persistent directory instead of /tmp (which OS can clear)
# Updated: 2026-01-16 - REPLAY MODE: Using /tmp for isolated replay state
spring.kafka.streams.state-dir=/tmp/kafka-streams-replay/${spring.application.name}

# APP-ID PREFIX - Change this to replay data from earliest with new consumer groups
# Example: "replay-20251229-" creates groups like "replay-20251229-unified-instrument-candle-processor"
# Updated: 2026-01-16 - REPLAY MODE for E2E testing
# This creates NEW consumer groups that will start from the beginning of all topics
kafka.streams.app-id-prefix=replay-e2e-20260116-

# KAFKA CONSUMER GROUP IDS - Change suffix to replay data
# Add "-v2", "-v3" etc to force new consumer groups and replay from earliest
# Updated: 2026-01-16 - REPLAY MODE for E2E testing
# Individual consumer groups
kafka.consumer.curated-group=replay-curated-consumer-20260116
kafka.consumer.mtis-group=replay-mtis-consumer-20260116
kafka.consumer.stats-group=replay-stats-consumer-20260116
kafka.consumer.quant-group=replay-quant-consumer-20260116
kafka.consumer.fudkii-group=replay-fudkii-consumer-20260116

# Serdes
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages=com.kotsin.consumer.model,com.kotsin.consumer.domain.model

# FIX: Offset reset - use LATEST for production to avoid replaying old data
# Using 'latest' with fresh consumer groups - backplay module will re-publish data
spring.kafka.streams.properties.auto.offset.reset=latest

# Processing guarantee
spring.kafka.streams.properties.processing.guarantee=at_least_once
spring.kafka.streams.properties.replication.factor=1

# Performance tuning
# OPTIMIZED: Increased from 100ms to 500ms to reduce disk I/O by ~80%
spring.kafka.streams.properties.commit.interval.ms=500
spring.kafka.streams.properties.statestore.cache.max.bytes=104857600
# OPTIMIZED: Reduced from 20 to 16 to match CPU cores (was over-provisioned)
# 16 threads = 16 CPU cores for optimal context switching
spring.kafka.streams.properties.num.stream.threads=16
# INCREASED: session.timeout from 30s to 60s for stability during bootstrap
# Prevents unnecessary consumer group rebalances during long API calls
spring.kafka.streams.properties.session.timeout.ms=60000
spring.kafka.streams.properties.heartbeat.interval.ms=10000
# ADDED: max.poll.interval increased to 5 minutes to handle bootstrap operations
spring.kafka.streams.properties.max.poll.interval.ms=300000

# Exception handlers - skip bad records instead of crashing
spring.kafka.streams.properties.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
spring.kafka.streams.properties.default.production.exception.handler=org.apache.kafka.streams.errors.LogAndContinueProductionExceptionHandler

# ============================================================================
# STAGE 1: INPUT TOPICS (Raw Data Sources)
# ============================================================================
input.topic.ticks=forwardtesting-data
input.topic.orderbook=Orderbook
input.topic.oi=OpenInterest

# ============================================================================
# STAGE 2: NEW UNIFIED INSTRUMENT CANDLE PROCESSOR
# ============================================================================
# Joins tick + orderbook + OI into InstrumentCandle
unified.processor.enabled=true
unified.input.topic.ticks=forwardtesting-data
unified.input.topic.orderbook=Orderbook
unified.input.topic.oi=OpenInterest
unified.output.topic.instrument=instrument-candle-1m
# FIX: Increased to 10s to allow options/futures from different partitions to arrive
# Options were arriving AFTER window emission with 2s grace (timing issue)
# 10s gives sufficient time for all family members to be collected
unified.window.grace.seconds=10

# Consumer fetch optimization for high-throughput orderbook consumption
# OPTIMIZED: Reduced poll records from 2000 to 500 for smoother GC
# OPTIMIZED: Reduced fetch.min.bytes from 2MB to 512KB for lower latency
unified.processor.max.poll.records=500
unified.processor.fetch.min.bytes=524288
unified.processor.fetch.max.wait.ms=50

# ============================================================================
# STAGE 3: FAMILY CANDLE PROCESSOR
# ============================================================================
# Groups instruments into family candles
family.candle.processor.enabled=true
# FIX: Increased to 10s to allow options from different partitions to arrive
# Options were arriving AFTER window emission with 2s grace (timing issue)
family.candle.window.grace.seconds=10
family.candle.cache.ttl.hours=24
family.cache.refresh.on.miss=true

# ============================================================================
# STAGE 4: TIMEFRAME AGGREGATOR
# ============================================================================
# Aggregates 1m -> higher timeframes
timeframe.aggregator.enabled=true
# INCREASED: 60 second grace period to handle late-arriving data during bootstrap
# Allows time for historical data to be fetched and merged with live stream
timeframe.aggregator.grace.seconds=60

# Family candle output topics
family.output.topics.1m=family-candle-1m
family.output.topics.2m=family-candle-2m
family.output.topics.3m=family-candle-3m
family.output.topics.5m=family-candle-5m
family.output.topics.15m=family-candle-15m
family.output.topics.30m=family-candle-30m
family.output.topics.1h=family-candle-1h
family.output.topics.2h=family-candle-2h
family.output.topics.4h=family-candle-4h
family.output.topics.1d=family-candle-1d

# ============================================================================
# STRATEGY MODULES (Consume from family-candle-* topics)
# ============================================================================

# IPU Processor (Institutional Participation & Urgency)
ipu.enabled=true
ipu.exhaustion.threshold=0.7

# VCP Processor (Volume Cluster Profile)
vcp.enabled=true
vcp.cluster.min.volume.ratio=1.5

# REGIME PROCESSOR (Index and Security)
regime.enabled=true
regime.index.smoothing=0.1
regime.security.ema.fast=8
regime.security.ema.slow=21

# FMA PROCESSOR (Final Magnitude Assembly)
# ENABLED for testing - need to see failure cases
fma.enabled=true
fma.cache.ttl.ms=300000

# TRADING SIGNAL PROCESSOR
# ENABLED for testing - need to see failure cases
signal.enabled=true
signal.cache.ttl.ms=120000

# ============================================================================
# CURATED SIGNALS (High-Quality Filtered Signals)
# ============================================================================
# ENABLED for testing - need to see failure cases
curated.enabled=true

# F&O API Configuration - DISABLED (using FamilyCandle data instead)
# The FuturesOptionsService API doesn't exist - we use FamilyCandle data directly
curated.fo.enabled=false
curated.min.magnitude=0.6
curated.min.confirmation.count=3
curated.output.topic=curated-trading-signals

# ============================================================================
# MTIS PROCESSOR (Multi-Timeframe Intelligence Score)
# ============================================================================
mtis.processor.enabled=true
mtis.processor.output.topic=family-score
mtis.producer.batch.size=16384
mtis.producer.linger.ms=5
mtis.producer.buffer.memory=33554432

# ============================================================================
# MASTER ARCHITECTURE (kotsin_FF1 Strategy)
# ============================================================================
masterarch.processor.enabled=true
masterarch.processor.index.scripcode=999920000
masterarch.processor.history.candles=100
masterarch.producer.batch.size=16384
masterarch.producer.linger.ms=5
masterarch.producer.buffer.memory=33554432
masterarch.consumer.group-id=masterarch-consumer-v12
masterarch.consumer.auto-offset-reset=earliest

# ============================================================================
# FUDKII PROCESSOR (Standalone FUDKII Strategy)
# ============================================================================
fudkii.processor.enabled=true
fudkii.processor.min.strength=0.55
fudkii.processor.history.candles=50

# ============================================================================
# OUTPUT TOPICS
# ============================================================================
trading.signals.output.topic=trading-signals
curated.signals.output.topic=curated-trading-signals

# ============================================================================
# SCRIPFINDER API CONFIGURATION
# ============================================================================
scripfinder.api.base-url=${SCRIPFINDER_API_URL:http://localhost:8102}
scripfinder.api.timeout.ms=${SCRIPFINDER_TIMEOUT_MS:3000}
scripfinder.api.circuit-breaker.failure-threshold=5
scripfinder.api.circuit-breaker.timeout-ms=60000

# ============================================================================
# INSTRUMENT CONFIGURATION (Externalized from hardcoded values)
# ============================================================================
instrument.volume.equity=1000000
instrument.volume.derivatives=5000000
instrument.volume.index=10000000
instrument.tick-size.cash=0.05
instrument.tick-size.derivatives=0.05
instrument.trade-classification.min-absolute=0.01
instrument.trade-classification.basis-points=0.0001
instrument.trade-classification.spread-multiplier=0.15

# ============================================================================
# CALCULATOR CONFIGURATION (All thresholds and algorithm parameters)
# ============================================================================
# VPIN Configuration
calculator.vpin.buckets-per-day=50
calculator.vpin.max-buckets=50
calculator.vpin.min-bucket-size=100.0
calculator.vpin.ewma-alpha=0.05

# OI Signal Detection
calculator.oi-signal.price-threshold=0.1
calculator.oi-signal.oi-threshold=2.0
calculator.oi-signal.option-oi-min-change=1000

# Futures Buildup Detection
calculator.futures-buildup.price-change-threshold=0.1
calculator.futures-buildup.oi-change-threshold=1.0

# Orderbook Microstructure
calculator.orderbook.lambda-window-size=100
calculator.orderbook.lambda-calc-frequency=20
calculator.orderbook.lambda-min-observations=10
calculator.orderbook.iceberg-history-size=20
calculator.orderbook.iceberg-cv-threshold=0.1
calculator.orderbook.iceberg-min-size=1000
calculator.orderbook.spoof-duration-threshold-ms=5000
calculator.orderbook.spoof-size-threshold=0.3

# Imbalance Bars
calculator.imbalance-bar.ewma-alpha=0.1
calculator.imbalance-bar.init-volume-imbalance=1000.0
calculator.imbalance-bar.init-dollar-imbalance=100000.0
calculator.imbalance-bar.init-tick-runs=10.0
calculator.imbalance-bar.init-volume-runs=5000.0
calculator.imbalance-bar.z-score-threshold=1.645

# ============================================================================
# CURATED SIGNAL - MULTI-TIMEFRAME LEVELS (5paisa Historical API)
# ============================================================================
# Uses same 5paisa historical data API as TradeExecutionModule
# API: /getHisDataFromFivePaisa?exch=n&exch_type=c&scrip_code=XXX&start_date=YYYY-MM-DD&end_date=YYYY-MM-DD&interval=1m
curated.levels.enabled=true
curated.levels.api.base-url=http://localhost:8002
# INCREASED: From 5000ms to 15000ms for reliability during market hours
curated.levels.api.timeout-ms=15000
# Exchange: n=NSE, m=MCX (lowercase as per API)
curated.levels.api.exch=n
# Exchange Type: c=Cash, d=Derivatives (lowercase as per API)
curated.levels.api.exch-type=c

# ============================================================================
# BOOTSTRAP EXECUTOR CONFIGURATION (Historical API Thread Pool)
# ============================================================================
# Dedicated 4-thread pool for fetching historical candle data from 5paisa API
# Prevents blocking Kafka consumer threads during bootstrap operations
bootstrap.executor.pool.size=4
bootstrap.executor.queue.capacity=100
bootstrap.executor.thread.prefix=bootstrap-hist-api-
# Max retry attempts for failed bootstraps (retries on next candle arrival)
bootstrap.max.retries=3
# HTTP timeouts for historical API calls
bootstrap.api.connect.timeout.ms=15000
bootstrap.api.read.timeout.ms=30000

# ============================================================================
# GATE CHAIN CONFIGURATION
# ============================================================================
# Enable/disable gate chain
gate.chain.enabled=true

# Hard Gate (Layer 1)
gate.hard.enabled=true
gate.hard.max.oi.age.minutes=15

# MTF Confluence Gate (Layer 2)
gate.mtf.enabled=true
gate.mtf.min.confirmations=3
gate.mtf.vcp.runway.threshold=0.5

# Signal Quality Gate (Layer 3)
gate.quality.enabled=true
gate.quality.min.inst.proxy=0.4
gate.quality.max.exhaustion=0.7
gate.quality.require.volume.confirmation=true

# Stats Gate (Layer 4 - Online Learning)
gate.stats.enabled=true
gate.stats.min.trades=5
gate.stats.min.win.rate=0.35
gate.stats.min.expectancy=-0.2
gate.stats.max.daily.losses=3
gate.stats.use.recent.window=true

# ============================================================================
# REDIS CONFIGURATION (for RedisCandleHistoryService)
# ============================================================================
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.database=${REDIS_DB:0}
spring.data.redis.timeout=2000ms
# OPTIMIZED: Increased pool size to handle 16 Kafka threads + enrichment threads
spring.data.redis.lettuce.pool.max-active=20
spring.data.redis.lettuce.pool.max-idle=16
spring.data.redis.lettuce.pool.min-idle=4
redis.candle.history.ttl.hours=48

# ============================================================================
# MONGODB CONFIGURATION (for SignalStats, SignalHistory)
# ============================================================================
spring.data.mongodb.uri=${MONGODB_URI:mongodb://localhost:27017/tradeIngestion}
spring.data.mongodb.auto-index-creation=true

# ============================================================================
# LOGGING
# ============================================================================
logging.level.root=INFO
logging.level.com.kotsin.consumer=DEBUG
logging.level.com.kotsin.consumer.infrastructure.kafka=DEBUG
logging.level.com.kotsin.consumer.domain.service=DEBUG
logging.level.com.kotsin.consumer.processor=DEBUG
logging.level.com.kotsin.consumer.service=DEBUG
logging.level.com.kotsin.consumer.regime=DEBUG
logging.level.com.kotsin.consumer.signal=DEBUG
logging.level.com.kotsin.consumer.capital=DEBUG
logging.level.com.kotsin.consumer.curated=DEBUG
logging.level.com.kotsin.consumer.score=DEBUG
logging.level.org.apache.kafka=WARN

# ============================================================================
# DEEP DEBUG: ENRICHMENT PIPELINE (TRACE level for maximum detail)
# ============================================================================
# Set to TRACE for step-by-step debugging, DEBUG for summaries, INFO for key events only
# Comment out or change to DEBUG/INFO after debugging session
logging.level.com.kotsin.consumer.enrichment=TRACE
logging.level.com.kotsin.consumer.enrichment.EnrichedQuantScoreCalculator=TRACE
logging.level.com.kotsin.consumer.enrichment.analyzer.FamilyContextAnalyzer=TRACE
logging.level.com.kotsin.consumer.enrichment.tracker.SwingPointTracker=TRACE
logging.level.com.kotsin.consumer.enrichment.tracker.SessionStructureTracker=TRACE
logging.level.com.kotsin.consumer.enrichment.detector.EventDetector=TRACE
logging.level.com.kotsin.consumer.enrichment.signal.SignalGenerator=TRACE

# ============================================================================
# DEEP DEBUG: TRADING STATE MACHINE & STRATEGIES (DEBUG/TRACE for signal flow)
# ============================================================================
# STATE_MGR_DIAG, FUDKII_DIAG, PIVOT_DIAG, PIPELINE_DIAG, ENRICH_DIAG, TECH_DIAG
logging.level.com.kotsin.consumer.trading=DEBUG
logging.level.com.kotsin.consumer.trading.state.InstrumentStateManager=DEBUG
logging.level.com.kotsin.consumer.trading.strategy.FudkiiStrategy=DEBUG
logging.level.com.kotsin.consumer.trading.strategy.PivotRetestStrategy=DEBUG
logging.level.com.kotsin.consumer.enrichment.enricher.TechnicalIndicatorEnricher=DEBUG

# Pattern with timestamp
logging.pattern.console=%d{HH:mm:ss.SSS} %-5level [%thread] %logger{36} - %msg%n

# ============================================================================
# PAPER TRADE EXECUTOR (E2E Testing with Backplay)
# ============================================================================
# Enabled for replay testing - tracks signals against price data
paper.trade.executor.enabled=true
paper.trade.executor.signal.topic=trading-signals-v2
paper.trade.executor.price.topic=family-candle-1m
paper.trade.executor.group.id=replay-paper-executor-20260116
paper.trade.executor.price.group.id=replay-paper-price-20260116
paper.trade.executor.slippage.bps=5
paper.trade.executor.max.active.positions=100
paper.trade.executor.position.timeout.minutes=240
paper.trade.executor.enable.partial.exits=false
