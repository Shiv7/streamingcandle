# ============================================================================
# STREAMINGCANDLE - END-TO-END PIPELINE CONFIGURATION
# ============================================================================
# Combined: NEW family candle pipeline + EXISTING strategy modules

spring.profiles.default=production
spring.application.name=streamingcandle
server.port=${SERVER_PORT:8081}

# ============================================================================
# KAFKA STREAMS CONFIGURATION
# ============================================================================
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.streams.application-id=${KAFKA_APP_ID:unified-family-processor-v2}
spring.kafka.streams.client-id=streamingcandle-family
# FIXED: Use persistent directory instead of /tmp (which OS can clear)
# Updated: 2026-01-16 - REPLAY MODE: Using /tmp for isolated replay state
spring.kafka.streams.state-dir=/tmp/kafka-streams-replay/${spring.application.name}

# APP-ID PREFIX - Change this to replay data from earliest with new consumer groups
# Example: "replay-20251229-" creates groups like "replay-20251229-unified-instrument-candle-processor"
# Updated: 2026-01-31 - LOGGING TEST MODE
kafka.streams.app-id-prefix=replay-20260201-1626-fresh-

# KAFKA CONSUMER GROUP IDS - Fresh groups for replay
# Updated: 2026-02-01 - REPLAY MODE
kafka.consumer.curated-group=replay-curated-consumer-20260201-1626-fresh
kafka.consumer.mtis-group=replay-mtis-consumer-20260201-1626-fresh
kafka.consumer.stats-group=replay-stats-consumer-20260201-1626-fresh
kafka.consumer.quant-group=logging-test-quant-20260131
kafka.consumer.fudkii-group=logging-test-fudkii-20260131

# Serdes
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages=com.kotsin.consumer.model,com.kotsin.consumer.domain.model

# Offset reset - EARLIEST for logging test to replay all data
spring.kafka.streams.properties.auto.offset.reset=earliest

# Processing guarantee
spring.kafka.streams.properties.processing.guarantee=at_least_once
spring.kafka.streams.properties.replication.factor=1

# Performance tuning
# OPTIMIZED: Increased from 100ms to 500ms to reduce disk I/O by ~80%
spring.kafka.streams.properties.commit.interval.ms=500
spring.kafka.streams.properties.statestore.cache.max.bytes=104857600
# OPTIMIZED: Reduced from 20 to 16 to match CPU cores (was over-provisioned)
# 16 threads = 16 CPU cores for optimal context switching
spring.kafka.streams.properties.num.stream.threads=16
# INCREASED: session.timeout from 30s to 60s for stability during bootstrap
# Prevents unnecessary consumer group rebalances during long API calls
spring.kafka.streams.properties.session.timeout.ms=60000
spring.kafka.streams.properties.heartbeat.interval.ms=10000
# ADDED: max.poll.interval increased to 5 minutes to handle bootstrap operations
spring.kafka.streams.properties.max.poll.interval.ms=300000

# Exception handlers - skip bad records instead of crashing
spring.kafka.streams.properties.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
spring.kafka.streams.properties.default.production.exception.handler=org.apache.kafka.streams.errors.LogAndContinueProductionExceptionHandler

# Topic configuration - 16 partitions to match CPU cores
kafka.topic.partitions=16
kafka.topic.replication-factor=1

# ============================================================================
# STAGE 1: INPUT TOPICS (Raw Data Sources)
# ============================================================================
input.topic.ticks=forwardtesting-data
input.topic.orderbook=Orderbook
input.topic.oi=OpenInterest

# ============================================================================
# STAGE 2: NEW UNIFIED INSTRUMENT CANDLE PROCESSOR
# ============================================================================
# Joins tick + orderbook + OI into InstrumentCandle
unified.processor.enabled=true
unified.input.topic.ticks=forwardtesting-data
unified.input.topic.orderbook=Orderbook
unified.input.topic.oi=OpenInterest
unified.output.topic.instrument=instrument-candle-1m
# FIX: Increased to 10s to allow options/futures from different partitions to arrive
# Options were arriving AFTER window emission with 2s grace (timing issue)
# 10s gives sufficient time for all family members to be collected
unified.window.grace.seconds=10

# Consumer fetch optimization for high-th2roughput orderbook consumption
# OPTIMIZED: Reduced poll records from 2000 to 500 for smoother GC
# OPTIMIZED: Reduced fetch.min.bytes from 2MB to 512KB for lower latency
unified.processor.max.poll.records=500
unified.processor.fetch.min.bytes=524288
unified.processor.fetch.max.wait.ms=50

# ============================================================================
# STAGE 3: FAMILY CANDLE PROCESSOR
# ============================================================================
# Groups instruments into family candles
family.candle.processor.enabled=true
# FIX: Increased to 10s to allow options from different partitions to arrive
# Options were arriving AFTER window emission with 2s grace (timing issue)
family.candle.window.grace.seconds=10
family.candle.cache.ttl.hours=24
family.cache.refresh.on.miss=true

# ============================================================================
# STAGE 4: TIMEFRAME AGGREGATOR
# ============================================================================
# Aggregates 1m -> higher timeframes
timeframe.aggregator.enabled=true
# INCREASED: 60 second grace period to handle late-arriving data during bootstrap
# Allows time for historical data to be fetched and merged with live stream
timeframe.aggregator.grace.seconds=60

# Family candle output topics
family.output.topics.1m=family-candle-1m
family.output.topics.2m=family-candle-2m
family.output.topics.3m=family-candle-3m
family.output.topics.5m=family-candle-5m
family.output.topics.15m=family-candle-15m
family.output.topics.30m=family-candle-30m
family.output.topics.1h=family-candle-1h
family.output.topics.2h=family-candle-2h
family.output.topics.4h=family-candle-4h
family.output.topics.1d=family-candle-1d

# ============================================================================
# LEGACY STRATEGY MODULES (DISABLED - Replaced by V2 Architecture)
# ============================================================================
# These old Kafka Streams processors are now replaced by V2 signal engine.
# V2 uses: VcpProcessor, IpuProcessor, PivotProcessor, FudkiiCalculator, SignalEngine

# IPU Processor (Institutional Participation & Urgency) - LEGACY
ipu.enabled=false
ipu.exhaustion.threshold=0.7

# VCP Processor (Volume Cluster Profile) - LEGACY
vcp.enabled=false
vcp.cluster.min.volume.ratio=1.5

# REGIME PROCESSOR (Index and Security) - LEGACY
regime.enabled=false
regime.index.smoothing=0.1
regime.security.ema.fast=8
regime.security.ema.slow=21

# FMA PROCESSOR (Final Magnitude Assembly) - LEGACY
fma.enabled=false
fma.cache.ttl.ms=300000

# TRADING SIGNAL PROCESSOR - LEGACY (replaced by V2 SignalEngine)
# signal.enabled is now controlled by signal.engine.enabled in V2 section
signal.cache.ttl.ms=120000

# ============================================================================
# CURATED SIGNALS - LEGACY (Can be re-enabled later with V2 data)
# ============================================================================
curated.enabled=false
curated.fo.enabled=false
curated.min.magnitude=0.6
curated.min.confirmation.count=3
curated.output.topic=curated-trading-signals

# ============================================================================
# MTIS PROCESSOR - LEGACY (Multi-Timeframe Intelligence Score)
# ============================================================================
mtis.processor.enabled=false
mtis.processor.output.topic=family-score
mtis.producer.batch.size=16384
mtis.producer.linger.ms=5
mtis.producer.buffer.memory=33554432

# ============================================================================
# MASTER ARCHITECTURE - LEGACY (kotsin_FF1 Strategy)
# ============================================================================
masterarch.processor.enabled=false
masterarch.processor.index.scripcode=999920000
masterarch.processor.history.candles=100
masterarch.producer.batch.size=16384
masterarch.producer.linger.ms=5
masterarch.producer.buffer.memory=33554432
masterarch.consumer.group-id=masterarch-consumer-v12
masterarch.consumer.auto-offset-reset=earliest

# ============================================================================
# FUDKII PROCESSOR - LEGACY (Replaced by V2 FudkiiCalculator)
# ============================================================================
fudkii.processor.enabled=false
fudkii.processor.min.strength=0.55
fudkii.processor.history.candles=50

# ============================================================================
# OUTPUT TOPICS
# ============================================================================
trading.signals.output.topic=trading-signals
curated.signals.output.topic=curated-trading-signals

# ============================================================================
# SCRIPFINDER API CONFIGURATION
# ============================================================================
scripfinder.api.base-url=${SCRIPFINDER_API_URL:http://localhost:8102}
scripfinder.api.timeout.ms=${SCRIPFINDER_TIMEOUT_MS:3000}
scripfinder.api.circuit-breaker.failure-threshold=5
scripfinder.api.circuit-breaker.timeout-ms=60000

# ============================================================================
# INSTRUMENT CONFIGURATION (Externalized from hardcoded values)
# ============================================================================
instrument.volume.equity=1000000
instrument.volume.derivatives=5000000
instrument.volume.index=10000000
instrument.tick-size.cash=0.05
instrument.tick-size.derivatives=0.05
instrument.trade-classification.min-absolute=0.01
instrument.trade-classification.basis-points=0.0001
instrument.trade-classification.spread-multiplier=0.15

# ============================================================================
# CALCULATOR CONFIGURATION (All thresholds and algorithm parameters)
# ============================================================================
# VPIN Configuration
calculator.vpin.buckets-per-day=50
calculator.vpin.max-buckets=50
calculator.vpin.min-bucket-size=100.0
calculator.vpin.ewma-alpha=0.05

# OI Signal Detection
calculator.oi-signal.price-threshold=0.1
calculator.oi-signal.oi-threshold=2.0
calculator.oi-signal.option-oi-min-change=1000

# Futures Buildup Detection
calculator.futures-buildup.price-change-threshold=0.1
calculator.futures-buildup.oi-change-threshold=1.0

# Orderbook Microstructure
calculator.orderbook.lambda-window-size=100
calculator.orderbook.lambda-calc-frequency=20
calculator.orderbook.lambda-min-observations=10
calculator.orderbook.iceberg-history-size=20
calculator.orderbook.iceberg-cv-threshold=0.1
calculator.orderbook.iceberg-min-size=1000
calculator.orderbook.spoof-duration-threshold-ms=5000
calculator.orderbook.spoof-size-threshold=0.3

# Imbalance Bars
calculator.imbalance-bar.ewma-alpha=0.1
calculator.imbalance-bar.init-volume-imbalance=1000.0
calculator.imbalance-bar.init-dollar-imbalance=100000.0
calculator.imbalance-bar.init-tick-runs=10.0
calculator.imbalance-bar.init-volume-runs=5000.0
calculator.imbalance-bar.z-score-threshold=1.645

# ============================================================================
# CURATED SIGNAL - MULTI-TIMEFRAME LEVELS (5paisa Historical API)
# ============================================================================
# Uses same 5paisa historical data API as TradeExecutionModule
# API: /getHisDataFromFivePaisa?exch=n&exch_type=c&scrip_code=XXX&start_date=YYYY-MM-DD&end_date=YYYY-MM-DD&interval=1m
curated.levels.enabled=true
curated.levels.api.base-url=http://localhost:8002
# INCREASED: From 5000ms to 15000ms for reliability during market hours
curated.levels.api.timeout-ms=15000
# Exchange: n=NSE, m=MCX (lowercase as per API)
curated.levels.api.exch=n
# Exchange Type: c=Cash, d=Derivatives (lowercase as per API)
curated.levels.api.exch-type=c

# ============================================================================
# BOOTSTRAP EXECUTOR CONFIGURATION (Historical API Thread Pool)
# ============================================================================
# Dedicated 4-thread pool for fetching historical candle data from 5paisa API
# Prevents blocking Kafka consumer threads during bootstrap operations
bootstrap.executor.pool.size=4
bootstrap.executor.queue.capacity=100
bootstrap.executor.thread.prefix=bootstrap-hist-api-
# Max retry attempts for failed bootstraps (retries on next candle arrival)
bootstrap.max.retries=3
# HTTP timeouts for historical API calls
bootstrap.api.connect.timeout.ms=15000
bootstrap.api.read.timeout.ms=30000

# ============================================================================
# GATE CHAIN CONFIGURATION
# ============================================================================
# Enable/disable gate chain
gate.chain.enabled=true

# Hard Gate (Layer 1)
gate.hard.enabled=true
gate.hard.max.oi.age.minutes=15

# MTF Confluence Gate (Layer 2)
gate.mtf.enabled=true
gate.mtf.min.confirmations=3
gate.mtf.vcp.runway.threshold=0.5

# Signal Quality Gate (Layer 3)
gate.quality.enabled=true
gate.quality.min.inst.proxy=0.4
gate.quality.max.exhaustion=0.7
gate.quality.require.volume.confirmation=true

# Stats Gate (Layer 4 - Online Learning)
gate.stats.enabled=true
gate.stats.min.trades=5
gate.stats.min.win.rate=0.35
gate.stats.min.expectancy=-0.2
gate.stats.max.daily.losses=3
gate.stats.use.recent.window=true

# ============================================================================
# REDIS CONFIGURATION (for RedisCandleHistoryService)
# ============================================================================
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.database=${REDIS_DB:0}
spring.data.redis.timeout=2000ms
# OPTIMIZED: Increased pool size to handle 16 Kafka threads + enrichment threads
spring.data.redis.lettuce.pool.max-active=20
spring.data.redis.lettuce.pool.max-idle=16
spring.data.redis.lettuce.pool.min-idle=4
redis.candle.history.ttl.hours=48

# ============================================================================
# MONGODB CONFIGURATION (for SignalStats, SignalHistory)
# ============================================================================
spring.data.mongodb.uri=${MONGODB_URI:mongodb://localhost:27017/tradeIngestion}
spring.data.mongodb.auto-index-creation=true

# ============================================================================
# LOGGING
# ============================================================================
logging.level.root=INFO
logging.level.com.kotsin.consumer=DEBUG
logging.level.com.kotsin.consumer.infrastructure.kafka=DEBUG
logging.level.com.kotsin.consumer.domain.service=DEBUG
logging.level.com.kotsin.consumer.processor=DEBUG
logging.level.com.kotsin.consumer.service=DEBUG
logging.level.com.kotsin.consumer.regime=DEBUG
logging.level.com.kotsin.consumer.signal=DEBUG
logging.level.com.kotsin.consumer.capital=DEBUG
logging.level.com.kotsin.consumer.curated=DEBUG
logging.level.com.kotsin.consumer.score=DEBUG
logging.level.com.kotsin.consumer.aggregator=DEBUG
logging.level.com.kotsin.consumer.event=TRACE
logging.level.org.apache.kafka=WARN

# ============================================================================
# DEEP DEBUG: ENRICHMENT PIPELINE (TRACE level for maximum detail)
# ============================================================================
# Set to TRACE for step-by-step debugging, DEBUG for summaries, INFO for key events only
# Comment out or change to DEBUG/INFO after debugging session
logging.level.com.kotsin.consumer.enrichment=TRACE
logging.level.com.kotsin.consumer.enrichment.EnrichedQuantScoreCalculator=TRACE
logging.level.com.kotsin.consumer.enrichment.analyzer.FamilyContextAnalyzer=TRACE
logging.level.com.kotsin.consumer.enrichment.tracker.SwingPointTracker=TRACE
logging.level.com.kotsin.consumer.enrichment.tracker.SessionStructureTracker=TRACE
logging.level.com.kotsin.consumer.enrichment.detector.EventDetector=TRACE
logging.level.com.kotsin.consumer.enrichment.signal.SignalGenerator=TRACE

# ============================================================================
# DEEP DEBUG: TRADING STATE MACHINE & STRATEGIES (DEBUG/TRACE for signal flow)
# ============================================================================
# STATE_MGR_DIAG, FUDKII_DIAG, PIVOT_DIAG, PIPELINE_DIAG, ENRICH_DIAG, TECH_DIAG
logging.level.com.kotsin.consumer.trading=DEBUG
logging.level.com.kotsin.consumer.trading.state.InstrumentStateManager=DEBUG
logging.level.com.kotsin.consumer.trading.strategy.FudkiiStrategy=DEBUG
logging.level.com.kotsin.consumer.trading.strategy.PivotRetestStrategy=DEBUG
logging.level.com.kotsin.consumer.enrichment.enricher.TechnicalIndicatorEnricher=DEBUG

# ============================================================================
# DEEP DEBUG: PIVOT & HISTORICAL DATA INTEGRATION
# ============================================================================
# Set to DEBUG for pivot-related logging, TRACE for maximum detail
# PIVOT_LEVEL, PIVOT_CONFLUENCE, HIST_BOOTSTRAP, FAST_ANALYTICS
logging.level.com.kotsin.consumer.service.PivotLevelService=DEBUG
logging.level.com.kotsin.consumer.service.HistoricalDataBootstrapService=INFO
logging.level.com.kotsin.consumer.client.FastAnalyticsClient=DEBUG
logging.level.com.kotsin.consumer.signal.analyzer.PivotConfluenceAnalyzer=DEBUG

# ============================================================================
# DEEP DEBUG: STRATEGY TRIGGERS (FUDKII + PIVOT CONFLUENCE)
# ============================================================================
# FUDKII_TRIGGER, PIVOT_TRIGGER - detailed logging for both strategies
logging.level.com.kotsin.consumer.signal.trigger=DEBUG
logging.level.com.kotsin.consumer.signal.trigger.FudkiiSignalTrigger=DEBUG
logging.level.com.kotsin.consumer.signal.trigger.PivotConfluenceTrigger=DEBUG
logging.level.com.kotsin.consumer.signal.engine.SignalEngine=DEBUG

# Pattern with timestamp
logging.pattern.console=%d{HH:mm:ss.SSS} %-5level [%thread] %logger{36} - %msg%n

# ============================================================================
# PAPER TRADE EXECUTOR (E2E Testing with Backplay)
# ============================================================================
# Enabled for replay testing - tracks signals against price data
paper.trade.executor.enabled=true
paper.trade.executor.signal.topic=trading-signals-v2
paper.trade.executor.price.topic=family-candle-1m
paper.trade.executor.group.id=replay-paper-executor-20260116
paper.trade.executor.price.group.id=replay-paper-price-20260116
paper.trade.executor.slippage.bps=5
paper.trade.executor.max.active.positions=100
paper.trade.executor.position.timeout.minutes=240
paper.trade.executor.enable.partial.exits=false

# ============================================================================
# V2 ARCHITECTURE: INDEPENDENT AGGREGATORS (NEW - REFACTORED)
# ============================================================================
# The v2 architecture replaces the complex Kafka Streams joins with simple
# independent consumers. Each data source (tick, orderbook, OI) is aggregated
# separately and merged at query time.
#
# Benefits:
# - No join failures or fallback logic
# - No complex Kafka Streams state stores
# - Clear data lineage and separation of concerns
# - On-demand timeframe aggregation
# - Simpler debugging and monitoring

# ============================================================================
# V2 TICK AGGREGATOR
# ============================================================================
# Independent Kafka consumer for tick data (forwardtesting-data topic)
v2.tick.aggregator.enabled=true
v2.tick.input.topic=forwardtesting-data
v2.tick.output.topic=tick-candles-1m
v2.tick.consumer.group=replay-20260201-1820-v1-tick-agg
v2.tick.aggregator.threads=4

# ============================================================================
# V2 ORDERBOOK AGGREGATOR
# ============================================================================
# Independent Kafka consumer for orderbook data
v2.orderbook.aggregator.enabled=true
v2.orderbook.input.topic=Orderbook
v2.orderbook.output.topic=orderbook-metrics-1m
v2.orderbook.consumer.group=replay-20260201-1801-v1-ob-agg
v2.orderbook.aggregator.threads=2

# ============================================================================
# V2 OI AGGREGATOR
# ============================================================================
# Independent Kafka consumer for Open Interest data
v2.oi.aggregator.enabled=true
v2.oi.input.topic=OpenInterest
v2.oi.output.topic=oi-metrics-1m
v2.oi.consumer.group=replay-20260201-1801-v1-oi-agg
v2.oi.aggregator.threads=2

# ============================================================================
# V2 TIMEFRAME AGGREGATION
# ============================================================================
# Background service for pre-computing popular timeframes (5m, 15m, 30m, 1h)
v2.timeframe.aggregation.enabled=true
v2.timeframe.aggregation.threads=2

# ============================================================================
# V2 REDIS CACHE SETTINGS
# ============================================================================
# TTL for latest candle cache (minutes)
v2.cache.tick.latest.ttl.minutes=5
# TTL for history list cache (hours)
v2.cache.tick.history.ttl.hours=24
# Max candles to keep in history list
v2.cache.tick.history.max.size=500

# ============================================================================
# V2 STRATEGY STATE SETTINGS
# ============================================================================
# TTL for strategy state cache (minutes)
v2.strategy.state.cache.ttl.minutes=30
# Enable/disable Redis caching for strategy state
v2.strategy.state.cache.enabled=true

# ============================================================================
# V2 SIGNAL ENGINE CONFIGURATION
# ============================================================================
# Enable/disable the signal engine
signal.engine.enabled=true
# Processing interval (ms) - how often to check for signals
signal.engine.schedule.interval.ms=5000
# Primary timeframe for signal detection
signal.engine.primary.timeframe=5m

# Signal Thresholds - LOWERED for realistic trading
# WATCH threshold - minimum FUDKII score to enter WATCH state
signal.watch.threshold=20
# ACTIVE threshold - minimum FUDKII score to enter ACTIVE state
signal.active.threshold=35
# Minimum confidence required for signal
signal.confidence.min=0.25

# FIX #3: Imbalance triggers (VIB/DIB/TRB) are now optional for ACTIVE
# Set to true to require imbalance for ACTIVE trigger (original strict behavior)
signal.active.require.imbalance=false
# Score boost when imbalance is present (added to composite score)
signal.active.imbalance.boost=15

# Signal Expiry Settings
# How long a WATCH signal stays valid before expiring (minutes)
signal.watch.expiry.minutes=30
# How long an ACTIVE signal stays valid before expiring (minutes)
signal.active.expiry.minutes=120

# FUDKII Component Weights (must sum to 1.0)
signal.fudkii.weight.flow=0.15
signal.fudkii.weight.urgency=0.20
signal.fudkii.weight.direction=0.25
signal.fudkii.weight.kyle=0.10
signal.fudkii.weight.imbalance=0.15
signal.fudkii.weight.intensity=0.15

# Signal Engine Integration Settings
signal.engine.gate.enabled=true
signal.engine.papertrade.enabled=true
# Dynamic symbol discovery - process ALL symbols from Redis
signal.engine.dynamic.symbols=true
# Fallback symbols if dynamic discovery is disabled (comma-separated)
signal.engine.symbols=
signal.engine.timeframe=5m

# ============================================================================
# V2 TECHNICAL INDICATORS CONFIGURATION
# ============================================================================
# RSI Settings
indicator.rsi.period=14
indicator.rsi.overbought=70
indicator.rsi.oversold=30

# MACD Settings
indicator.macd.fast.period=12
indicator.macd.slow.period=26
indicator.macd.signal.period=9

# Bollinger Bands Settings
indicator.bb.period=20
indicator.bb.multiplier=2.0

# SuperTrend Settings
indicator.supertrend.period=10
indicator.supertrend.multiplier=3.0

# EMA Periods
indicator.ema.fast=9
indicator.ema.medium=20
indicator.ema.slow=50

# ATR Settings
indicator.atr.period=14

# ADX Settings
indicator.adx.period=14
indicator.adx.trend.threshold=25

# Stochastic Settings
indicator.stoch.k.period=14
indicator.stoch.d.period=3

# ============================================================================
# V2 OPTIONS GREEKS CONFIGURATION
# ============================================================================
# Risk-free rate for Black-Scholes (India)
options.risk.free.rate=0.07

# IV Calculation Settings
options.iv.max.iterations=100
options.iv.precision=0.0001
options.iv.default=0.20

# ============================================================================
# V2 SMC ANALYZER CONFIGURATION
# ============================================================================
# Order Block Detection
smc.orderblock.min.move.percent=0.3
smc.orderblock.max.structures=50

# Fair Value Gap Detection
smc.fvg.min.size.percent=0.1
smc.fvg.max.structures=50

# Liquidity Detection
smc.liquidity.swing.lookback=5
smc.liquidity.equal.tolerance=0.001

# ============================================================================
# V2 REGIME DETECTION CONFIGURATION
# ============================================================================
# ADX Thresholds
regime.adx.strong=40
regime.adx.moderate=25
regime.adx.weak=15

# RSI Thresholds
regime.rsi.overbought=70
regime.rsi.oversold=30

# Volatility Percentiles
regime.volatility.high=80
regime.volatility.low=20

# ============================================================================
# V2 SESSION STRUCTURE CONFIGURATION
# ============================================================================
# Market Hours (IST)
session.market.open=09:15
session.market.close=15:30

# Opening Range Periods (minutes after open)
session.or.15=15
session.or.30=30
session.or.60=60

# VWAP Settings
session.vwap.bands=2

# ============================================================================
# V2 BREAKOUT DETECTION CONFIGURATION
# ============================================================================
# Breakout Thresholds
breakout.threshold.percent=0.1
breakout.retest.tolerance.percent=0.3
breakout.volume.confirm.ratio=1.5

# Max Active Breakouts per Symbol
breakout.max.active=20

# ============================================================================
# V2 PAPER TRADE CONFIGURATION
# ============================================================================
# Initial Capital
papertrade.initial.capital=100000

# Risk Management
papertrade.max.positions=5
papertrade.risk.per.trade=0.02

# Commission
papertrade.commission.per.trade=20

# ============================================================================
# V2 SIGNAL STATS CONFIGURATION
# ============================================================================
# Stats Retention
stats.history.max.records=10000
stats.history.retention.days=90

# Performance Thresholds
stats.win.rate.excellent=65
stats.win.rate.good=55
stats.profit.factor.excellent=2.0
stats.profit.factor.good=1.5

# ============================================================================
# V2 GATE CHAIN CONFIGURATION (Extended)
# ============================================================================
# Gate Weights (must be 0-1)
gate.volume.weight=0.15
gate.trend.weight=0.20
gate.risk.reward.weight=0.20
gate.momentum.weight=0.15
gate.vwap.weight=0.10
gate.time.of.day.weight=0.10
gate.fudkii.weight=0.20

# Gate Requirements
gate.volume.required=false
gate.trend.required=true
gate.risk.reward.required=true
gate.momentum.required=false
gate.vwap.required=false
gate.time.of.day.required=false
gate.fudkii.required=false

# Gate Thresholds - LOWERED for realistic trading
gate.volume.min.ratio=1.0
gate.risk.reward.min=1.2
gate.momentum.rsi.overbought=75
gate.momentum.rsi.oversold=25
gate.fudkii.min.score=20

# ============================================================================
# FASTANALYTICS API CONFIGURATION (Python API on port 8002)
# ============================================================================
# Base URL for FastAnalytics Python API running on port 8002
# This API provides access to FivePaisa historical data and pivot calculations
fastanalytics.base-url=http://localhost:8002
# Connection timeout for API calls (ms)
fastanalytics.connect-timeout-ms=5000
# Read timeout for API calls (ms) - increased for large historical data fetches
fastanalytics.read-timeout-ms=60000

# ============================================================================
# HISTORICAL DATA BOOTSTRAP CONFIGURATION
# ============================================================================
# Enable/disable historical data bootstrap on startup
# When enabled, fetches 40 days of 1m candles for each symbol
bootstrap.historical.enabled=true
# Number of days of historical 1-minute candle data to fetch
bootstrap.historical.days=40
# Number of parallel threads for bootstrapping
bootstrap.historical.threads=4
# Delay before starting bootstrap after startup (seconds)
bootstrap.historical.delay-seconds=10
# Enable automatic startup bootstrap from scripFinder API
bootstrap.historical.startup.enabled=true

# ============================================================================
# PIVOT LEVEL SERVICE CONFIGURATION
# ============================================================================
# Cache TTL for pivot levels (minutes)
pivot.cache.ttl-minutes=60
# Scheduled refresh cron (9 AM on trading days)
pivot.refresh.cron=0 0 9 * * MON-FRI

# ============================================================================
# PIVOT CONFLUENCE ANALYSIS CONFIGURATION
# ============================================================================
# Threshold for confluence detection (percentage) - pivots within this range are considered confluent
pivot.confluence.threshold-percent=0.5
# CPR width thresholds (percentage of price)
pivot.cpr.thin-threshold=0.5
pivot.cpr.ultra-thin-threshold=0.3

# ============================================================================
# BOUNCE DETECTION CONFIGURATION
# ============================================================================
# Price must be within this percentage of a pivot level to detect a bounce
bounce.detection.proximity-threshold=0.3
# Minimum volume ratio (vs average) to confirm a bounce
bounce.detection.volume-confirm-ratio=1.2
# Minimum candles to look back for bounce confirmation
bounce.detection.lookback-candles=3

# ============================================================================
# PIVOT BOOST CONFIGURATION (Score additions to FUDKII)
# ============================================================================
# Boost for thin CPR detection (high breakout probability)
pivot.boost.thin-cpr=5.0
# Boost for ultra-thin CPR (very high breakout probability)
pivot.boost.ultra-thin-cpr=10.0
# Boost for strong confluence (3+ timeframe pivots aligned)
pivot.boost.strong-confluence=8.0
# Boost for bounce detection at pivot
pivot.boost.bounce-at-pivot=7.0
# Boost for high-confidence bounce (bounce + confluence + thin CPR)
pivot.boost.high-confidence-bounce=12.0

# ============================================================================
# PATTERN ANALYZER CONFIGURATION
# ============================================================================
# Enable/disable pattern detection
pattern.detection.enabled=true
# Minimum confidence threshold for patterns (0-1)
pattern.min.confidence=0.6
# Body ratio threshold for pattern detection
pattern.body.ratio.threshold=0.3
# Doji body ratio (smaller = stricter doji detection)
pattern.doji.body.ratio=0.1

# Multi-Timeframe Pattern Detection
# Enable MTF pattern detection (detects patterns on multiple timeframes)
pattern.detection.mtf.enabled=true
# Timeframes for pattern detection (comma-separated)
# Supported: 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 1d
pattern.detection.timeframes=5m,15m,30m,1h,2h,4h,1d

# ============================================================================
# PATTERN SIGNAL PRODUCER CONFIGURATION
# ============================================================================
# Enable/disable pattern signal publishing
pattern.signal.enabled=true
# Kafka topic for pattern signals
pattern.signal.kafka.topic=pattern-signals
# Redis key prefix for pattern data
pattern.signal.redis.prefix=pattern:
# TTL for pattern data in Redis (minutes)
pattern.signal.redis.ttl.minutes=30
# Minimum confidence for publishing (0-1)
pattern.signal.min.confidence=0.6

# ============================================================================
# QUANT SCORE PRODUCER CONFIGURATION
# ============================================================================
# Enable/disable quant score publishing
quant.score.enabled=true
# Kafka topic for quant scores
quant.score.kafka.topic=quant-scores
# Redis key prefix for quant scores
quant.score.redis.prefix=quant:score:
# TTL for quant score data in Redis (minutes)
quant.score.redis.ttl.minutes=10

# ============================================================================
# QUANT SCORE GATE CONFIGURATION
# ============================================================================
# Weight of quant score gate in chain (0-1)
gate.quant.weight=0.20
# Minimum FUDKII score required - LOWERED
gate.quant.min.score=20
# Minimum confidence required (0-1) - LOWERED
gate.quant.min.confidence=0.25
# Minimum aligned components (0-6) - LOWERED
gate.quant.min.alignment=2
# Is this gate required for signal approval - RELAXED
gate.quant.required=false

# ============================================================================
# PATTERN GATE CONFIGURATION
# ============================================================================
# Weight of pattern gate in chain (0-1)
gate.pattern.weight=0.15
# Minimum pattern confidence (0-1)
gate.pattern.min.confidence=0.6
# Is this gate required for signal approval
gate.pattern.required=false

# ============================================================================
# STRATEGY 1: FUDKII SIGNAL TRIGGER (SuperTrend + Bollinger Band)
# ============================================================================
# Trigger on 30m candle when SuperTrend flips AND close outside BB
# BULLISH: ST flips red→green AND close > BB_upper
# BEARISH: ST flips green→red AND close < BB_lower
fudkii.trigger.enabled=true
# Timeframe for FUDKII trigger (30m candles aggregated from 1m)
fudkii.trigger.timeframe=30m
# Bollinger Band period (20 candles)
fudkii.trigger.bb.period=20
# SuperTrend period (7 candles with ATR multiplier 3.0)
fudkii.trigger.st.period=7

# --- FUDKII TRIGGER FIXES (2026-02-01) ---
# FIX #1: BBST state is now automatically persisted to Redis for restart recovery

# FIX #2: Require both conditions (ST flip AND BB outside) - core strategy
# Set to false to allow OR condition (less strict)
fudkii.trigger.require.both.conditions=true

# FIX #4: ST flip debounce - remember flip for this many minutes
# Prevents missing signals when flip detection spans multiple processing cycles
fudkii.trigger.flip.debounce.minutes=10

# FIX #5: Log near-miss scenarios for debugging missed signals
fudkii.trigger.log.near.misses=true

# FIX #6: Historical data bootstrap - number of days to fetch from API
# This ensures we have enough data even if MongoDB is missing historical candles
fudkii.trigger.bootstrap.days-back=5

# FIX #7: MCX Support - Enable/disable MCX (exchange=M) FUDKII signals
# MCX uses different 30m boundaries: 9:00-9:30, 9:30-10:00, etc. up to 23:30
fudkii.trigger.mcx.enabled=true

# Kafka topic for FUDKII signals
fudkii.trigger.kafka.topic=kotsin_FUDKII

# ============================================================================
# FUKAA VOLUME FILTER (Filters FUDKII signals by volume surge)
# ============================================================================
# FUKAA = FUDKII + Volume Surge Filter
# At signal time T, checks if T-1 or T candle volume > 2x avg of last 6 candles
# If neither passes, signal enters watching mode for T+1 re-evaluation
fukaa.trigger.enabled=true
# Kafka topic for FUKAA signals (volume-confirmed FUDKII)
fukaa.trigger.kafka.topic=kotsin_FUKAA
# Volume multiplier threshold (2.0 = 2x average volume required)
fukaa.trigger.volume.multiplier=2.0
# Number of candles for average volume calculation (candles -3 to -8 from current)
fukaa.trigger.avg.candles=6
# Redis TTL for watching signals (minutes) - slightly more than 30m to cover T+1
fukaa.trigger.watching.ttl.minutes=35

# ============================================================================
# STRATEGY 2: PIVOT CONFLUENCE TRIGGER (HTF/LTF Price Action)
# ============================================================================
# Pure price action: HTF sets direction bias, LTF confirms entry
# Only trade in direction of HTF bias (no counter-trend trades)
pivot.confluence.trigger.enabled=true
# Minimum confluence levels for trigger (Daily + Weekly + Monthly pivots)
pivot.confluence.trigger.min.levels=2
# Minimum Risk:Reward ratio required
pivot.confluence.trigger.min.rr=1.5
# HTF weight for bias determination (Daily=0.4, 4H=0.3)
pivot.confluence.trigger.htf.weight=0.7
# LTF weight for confirmation (15m=0.2, 5m=0.1)
pivot.confluence.trigger.ltf.weight=0.3
# SMC Order Block confirmation required
pivot.confluence.trigger.smc.orderblock.required=false
# SMC FVG (Fair Value Gap) confirmation
pivot.confluence.trigger.smc.fvg.required=false
# Volume confirmation ratio (vs average)
pivot.confluence.trigger.volume.ratio=1.2
