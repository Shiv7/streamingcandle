# DEFAULT PROFILE = PRODUCTION (use -Dspring-boot.run.profiles=test to override)
spring.profiles.active=production

spring.application.name=consumer
server.port=8081
# MongoDB Configuration
spring.data.mongodb.uri=mongodb://localhost:27017/scripFinder
spring.data.mongodb.auto-index-creation=true

# Kafka Configuration for historical data
spring.kafka.bootstrap-servers=13.203.60.173:9094
spring.kafka.consumer.auto-offset-reset=earliest

# FIXED: Add missing consumer deserializer configuration
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=com.kotsin.consumer.model
spring.kafka.consumer.properties.spring.json.value.default.type=com.kotsin.consumer.model.TickData

# Producer configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

# CRITICAL FIX: Disable type headers to prevent ClassNotFoundException in consumers
# This allows consumers to use their own class definitions without package conflicts
spring.kafka.producer.properties.spring.json.add.type.headers=false

# Kafka Streams Configuration - PRODUCTION FIXES
spring.kafka.streams.application-id=candle-processor-ticktooneminprocessor
spring.kafka.streams.bootstrap-servers=13.203.60.173:9094
spring.kafka.streams.client-id=streamingcandle
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages=com.kotsin.consumer.model
spring.kafka.streams.properties.auto.offset.reset=earliest

# CRITICAL FIX: Use unique state directory path with application name and instance ID
spring.kafka.streams.state-dir=/home/ubuntu/kstreams/${spring.application.name}
# FIXED: at_least_once for single-broker (exactly_once_v2 needs replication â‰¥ 3)
spring.kafka.streams.properties.processing.guarantee=at_least_once

# Production reliability configurations
spring.kafka.streams.properties.commit.interval.ms=100
spring.kafka.streams.properties.statestore.cache.max.bytes=10485760
spring.kafka.streams.properties.session.timeout.ms=30000
spring.kafka.streams.properties.heartbeat.interval.ms=3000
spring.kafka.streams.properties.request.timeout.ms=40000
spring.kafka.streams.properties.retry.backoff.ms=100
spring.kafka.streams.properties.reconnect.backoff.ms=50

# REAL-TIME OPTIMIZATION: Low latency configurations
spring.kafka.streams.properties.linger.ms=5
spring.kafka.streams.properties.batch.size=1024
spring.kafka.streams.properties.buffer.memory=33554432

spring.kafka.streams.properties.spring.json.value.default.type=com.kotsin.consumer.model.TickData

# ============================================================================
# INFORMATION-DRIVEN BARS CONFIGURATION
# Based on "Advances in Financial Machine Learning" Chapter 2
# ============================================================================

# Enable information bars (VIB, DIB, TRB, VRB)
# CRITICAL: Multi-threshold approach (like 1min, 2min, 5min for time bars)
information.bars.enabled=true

# Threshold multipliers (like 1min, 2min, 5min for time bars)
# 1x = sensitive (high frequency), 2x = medium, 5x = stable (low frequency)
information.bars.thresholds=1.0,2.0,5.0

# VIB - Volume Imbalance Bars
information.bars.vib.enabled=true
information.bars.vib.min.ticks=10
information.bars.vib.warmup.samples=20

# DIB - Dollar Imbalance Bars  
information.bars.dib.enabled=true
information.bars.dib.min.ticks=10
information.bars.dib.warmup.samples=20

# TRB - Tick Runs Bars
information.bars.trb.enabled=true
information.bars.trb.min.ticks=10
information.bars.trb.warmup.samples=20

# VRB - Volume Runs Bars
information.bars.vrb.enabled=true
information.bars.vrb.min.ticks=10
information.bars.vrb.warmup.samples=20

# EWMA parameters for expected imbalance/run calculation
information.bars.ewma.span=100.0

# CRITICAL FIX: Added missing configuration (no more hardcoded values)

# ============================================================================
# MICROSTRUCTURE FEATURES CONFIGURATION
# Based on "Advances in Financial Machine Learning" Chapter 19
# ============================================================================

# Enable microstructure feature calculation
microstructure.enabled=true

# Kafka topics
microstructure.input.topic=Orderbook
microstructure.output.topic=microstructure-features

# Rolling window configuration
microstructure.window.size=50
microstructure.min.observations=20

# Emission strategy
# How often to emit features (milliseconds)
# 1000 = 1 second, 5000 = 5 seconds, 10000 = 10 seconds
microstructure.emit.interval.ms=1000
# Minimum expected volume (prevents division by zero, used during warmup)
information.bars.min.expected.volume=100.0

# Expected bar size for runs bars (TRB/VRB)
information.bars.expected.bar.size=50.0

# Kafka topics for information bars
information.bars.input.topic=forwardtesting-data
information.bars.vib.output.topic=volume-imbalance-bars
information.bars.dib.output.topic=dollar-imbalance-bars
information.bars.trb.output.topic=tick-runs-bars
information.bars.vrb.output.topic=volume-runs-bars

# Information bars application ID prefix (for unique consumer groups per deployment)
information.bars.app.id.prefix=information-bars

# ============================================================================
# CANDLESTICK OUTPUT TOPICS (Time-based bars)
# ============================================================================
candle.input.topic=forwardtesting-data
candle.output.topic.1min=1-min-candle
candle.output.topic.2min=2-min-candle
candle.output.topic.3min=3-min-candle
candle.output.topic.5min=5-min-candle
candle.output.topic.15min=15-min-candle
candle.output.topic.30min=30-min-candle

# ============================================================================
# OPEN INTEREST CONFIGURATION (Position-based signals)
# ============================================================================
openinterest.enabled=true
openinterest.input.topic=OpenInterest

# OI output topics (multiple timeframes like candles)
openinterest.output.topic.1min=1-min-oi
openinterest.output.topic.2min=2-min-oi
openinterest.output.topic.3min=3-min-oi
openinterest.output.topic.5min=5-min-oi
openinterest.output.topic.15min=15-min-oi
openinterest.output.topic.30min=30-min-oi

# ============================================================================
# INSTRUMENT FAMILY CACHE CONFIGURATION
# ============================================================================

# ScripFinder API configuration
instrument.api.base.url=http://13.203.60.173:8102

# Cache configuration
instrument.cache.refresh.cron=0 0 3 * * ?
instrument.cache.parallel.threads=10

# Redis configuration for instrument cache
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.timeout=3000ms
spring.data.redis.lettuce.pool.max-active=8
spring.data.redis.lettuce.pool.max-idle=8
spring.data.redis.lettuce.pool.min-idle=2
spring.data.redis.lettuce.pool.max-wait=-1ms

# ============================================================================
# UNIFIED MARKET DATA PROCESSOR CONFIGURATION
# ============================================================================

# Unified processor settings
unified.input.topic.ticks=forwardtesting-data
unified.input.topic.oi=OpenInterest
unified.input.topic.orderbook=Orderbook
unified.output.topic=enriched-market-data

# Kafka Streams application ID for unified processor
spring.kafka.streams.application-id=unified-market-processor

# Window configuration
unified.window.size.minutes=30
unified.window.grace.seconds=10

# Processing settings
unified.processing.batch.size=1000
unified.processing.linger.ms=100
