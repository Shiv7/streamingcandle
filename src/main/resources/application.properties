# DEFAULT PROFILE = PRODUCTION
# Default to replay profile unless overridden
spring.profiles.default=production

spring.application.name=streamingcandle
server.port=8081



# ============================================================================
# KAFKA STREAMS CONFIGURATION
# ============================================================================
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.streams.application-id=unified-market-processor
spring.kafka.streams.client-id=streamingcandle
spring.kafka.streams.state-dir=/tmp/kafka-streams/${spring.application.name}

# Serdes
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages=com.kotsin.consumer.model

# Offset reset - consume from latest (skip old problematic data)
spring.kafka.streams.properties.auto.offset.reset=earliest

# Processing guarantee (at_least_once or exactly_once_v2)
spring.kafka.streams.properties.processing.guarantee=at_least_once
spring.kafka.streams.properties.replication.factor=1

# Performance tuning
spring.kafka.streams.properties.commit.interval.ms=100
spring.kafka.streams.properties.statestore.cache.max.bytes=104857600
spring.kafka.streams.properties.num.stream.threads=1
spring.kafka.streams.properties.session.timeout.ms=30000
spring.kafka.streams.properties.heartbeat.interval.ms=3000
spring.kafka.streams.properties.request.timeout.ms=40000
spring.kafka.streams.properties.retry.backoff.ms=100
spring.kafka.streams.properties.reconnect.backoff.ms=50
spring.kafka.streams.properties.linger.ms=5
spring.kafka.streams.properties.batch.size=1024
spring.kafka.streams.properties.buffer.memory=33554432

# Topology optimization
spring.kafka.streams.properties.topology.optimization=all

# Exception handlers - skip bad records instead of crashing
spring.kafka.streams.properties.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
spring.kafka.streams.properties.default.production.exception.handler=org.apache.kafka.streams.errors.LogAndContinueProductionExceptionHandler

# Producer timestamp type
spring.kafka.streams.properties.producer.message.timestamp.type=CreateTime

# Redis removed: in-memory cache only

# ============================================================================
# UNIFIED MARKET DATA PROCESSOR CONFIGURATION
# ============================================================================
# Input topics
unified.input.topic.ticks=forwardtesting-data
unified.input.topic.oi=OpenInterest
unified.input.topic.orderbook=Orderbook

# âœ… P2-2 FIX: Windowing configuration (externalized from hardcoded values)
# Grace period: how long to wait for late-arriving data after window closes
# Trade-off: Higher grace = more complete data but higher latency
# NOTE: 1m candles are delayed by this amount due to suppression until window closes.
# Configure per-timeframe:
candles.window.grace.seconds.1m=5
candles.window.grace.seconds.multi=10

# Testing: enable to process only a single instrument (by Token)
candles.filter.enabled=true
candles.filter.token=123257

# VPIN configuration (dynamic)
candles.vpin.initial.bucket.size=10000.0
candles.vpin.adaptive.alpha=0.05
candles.vpin.max.buckets=50

# Imbalance thresholds and EWMA (adaptive)
candles.imbalance.ewma.alpha=0.1
candles.imbalance.initial.vib=1000.0
candles.imbalance.initial.dib=100000.0
candles.imbalance.initial.trb=10.0
candles.imbalance.initial.vrb=5000.0

# Trade classification thresholds
candles.classify.min.absolute=0.01
candles.classify.bps=0.0001
candles.classify.spread.multiplier=0.15

# Tick sizes
candles.ticksize.default=0.05
candles.ticksize.derivatives=0.05
candles.imbalance.q.zscore=1.645

# Orderbook filters and windowing
orderbook.filter.enabled=true
orderbook.filter.token=123257
orderbook.window.grace.seconds.1m=5
orderbook.window.grace.seconds.multi=10

# Open Interest (options) filters and windowing
oi.filter.enabled=true
oi.filter.token=123257
oi.window.grace.seconds.1m=5
oi.window.grace.seconds.multi=10
oi.value.scale=1.0

# OHLC always updates from price ticks; volume updates only when trade volume exists

# Intermediate topics (separate window aggregations per stream)
stream.intermediate.ohlcv.1m=intermediate-ohlcv-1m
stream.intermediate.ohlcv.2m=intermediate-ohlcv-2m
stream.intermediate.ohlcv.3m=intermediate-ohlcv-3m
stream.intermediate.ohlcv.5m=intermediate-ohlcv-5m
stream.intermediate.ohlcv.15m=intermediate-ohlcv-15m
stream.intermediate.ohlcv.30m=intermediate-ohlcv-30m

stream.intermediate.orderbook.1m=intermediate-orderbook-1m
stream.intermediate.orderbook.2m=intermediate-orderbook-2m
stream.intermediate.orderbook.3m=intermediate-orderbook-3m
stream.intermediate.orderbook.5m=intermediate-orderbook-5m
stream.intermediate.orderbook.15m=intermediate-orderbook-15m
stream.intermediate.orderbook.30m=intermediate-orderbook-30m

stream.intermediate.oi.1m=intermediate-oi-1m
stream.intermediate.oi.2m=intermediate-oi-2m
stream.intermediate.oi.3m=intermediate-oi-3m
stream.intermediate.oi.5m=intermediate-oi-5m
stream.intermediate.oi.15m=intermediate-oi-15m
stream.intermediate.oi.30m=intermediate-oi-30m

# Finalized candle topics
stream.outputs.candles.enabled=true
stream.outputs.candles.1m=candle-complete-1m
stream.outputs.candles.2m=candle-complete-2m
stream.outputs.candles.3m=candle-complete-3m
stream.outputs.candles.5m=candle-complete-5m
stream.outputs.candles.15m=candle-complete-15m
stream.outputs.candles.30m=candle-complete-30m-v2

# Family aggregation disabled; per-instrument streams only
stream.outputs.familyStructured.enabled=false

# ============================================================================
# LOGGING CONFIGURATION (Issue #13 Fix)
# ============================================================================
# Root log level
logging.level.root=INFO

# Application logs
logging.level.com.kotsin.consumer=INFO

# Kafka Streams (reduce noise)
logging.level.org.apache.kafka.streams=WARN
logging.level.org.springframework.kafka=WARN

trading.hours.validation.enabled=false
# DEBUG only for specific troubleshooting (comment out in production)
# logging.level.com.kotsin.consumer.service.CandleEmissionService=DEBUG
# logging.level.com.kotsin.consumer.service.InstrumentStateManager=DEBUG
