# DEFAULT PROFILE = PRODUCTION
spring.profiles.active=production

spring.application.name=streamingcandle
server.port=8081

# ============================================================================
# MONGODB CONFIGURATION
# ============================================================================
spring.data.mongodb.uri=mongodb://localhost:27017/tradeIngestion
spring.data.mongodb.auto-index-creation=true

# ============================================================================
# KAFKA STREAMS CONFIGURATION
# ============================================================================
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.streams.application-id=unified-market-processor1
spring.kafka.streams.client-id=streamingcandle
spring.kafka.streams.state-dir=/tmp/kafka-streams/${spring.application.name}

# Serdes
spring.kafka.streams.properties.default.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties.default.value.serde=org.springframework.kafka.support.serializer.JsonSerde
spring.kafka.streams.properties.spring.json.trusted.packages=com.kotsin.consumer.model

# Offset reset - consume from earliest
spring.kafka.streams.properties.auto.offset.reset=earliest

# Processing guarantee (at_least_once or exactly_once_v2)
spring.kafka.streams.properties.processing.guarantee=at_least_once

# Performance tuning
spring.kafka.streams.properties.commit.interval.ms=100
spring.kafka.streams.properties.statestore.cache.max.bytes=104857600
spring.kafka.streams.properties.num.stream.threads=2
spring.kafka.streams.properties.session.timeout.ms=30000
spring.kafka.streams.properties.heartbeat.interval.ms=3000
spring.kafka.streams.properties.request.timeout.ms=40000
spring.kafka.streams.properties.retry.backoff.ms=100
spring.kafka.streams.properties.reconnect.backoff.ms=50
spring.kafka.streams.properties.linger.ms=5
spring.kafka.streams.properties.batch.size=1024
spring.kafka.streams.properties.buffer.memory=33554432

# Topology optimization
spring.kafka.streams.properties.topology.optimization=all

# Deserialization exception handler
spring.kafka.streams.properties.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler

# Producer timestamp type
spring.kafka.streams.properties.producer.message.timestamp.type=CreateTime

# Redis removed: in-memory cache only

# ============================================================================
# UNIFIED MARKET DATA PROCESSOR CONFIGURATION
# ============================================================================
# Input topics
unified.input.topic.ticks=forwardtesting-data
unified.input.topic.oi=OpenInterest
unified.input.topic.orderbook=Orderbook

# Output topics
unified.output.topic=enriched-market-data

# ============================================================================
# DUAL EMISSION STRATEGY (Feature Flags)
# ============================================================================
# Enable enriched stream (partial updates every window, family-grouped)
# DEPRECATED: Disable enriched output; use finalized candle topics instead
stream.outputs.enriched.enabled=false

# Enable finalized candle emission (only on window close)
stream.outputs.candles.enabled=true

# Finalized candle topics (one per timeframe)
stream.outputs.candles.1m=candle-complete-1m
stream.outputs.candles.2m=candle-complete-2m
stream.outputs.candles.3m=candle-complete-3m
stream.outputs.candles.5m=candle-complete-5m
stream.outputs.candles.15m=candle-complete-15m
stream.outputs.candles.30m=candle-complete-30m

# Optional: Enable additional candle fields (vwap, hlc3, logReturn, etc.)
stream.outputs.candles.include-extras=false
